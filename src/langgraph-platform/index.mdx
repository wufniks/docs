---
title: Get started with LangGraph Platform
sidebarTitle: Get started
mode: wide
---

LangGraph Platform is a runtime for deploying and managing long-running, stateful agent workflows in production. It provides APIs for execution, persistence, monitoring, and scaling of agent applications. Agents built with [LangGraph](/oss/langgraph/overview) or other frameworks can be hosted on the platform and exposed through managed endpoints.

Choose from cloud, hybrid, or self-hosted deployments based on your infrastructure requirements. For more details, refer to the [Deployment options](/langgraph-platform/deployment-options) page.

## Quickstarts

<Columns cols={3}>

    <Card
        title="Run a LangGraph app locally"
        icon="laptop"
        href="/langgraph-platform/local-server"
        arrow="true"
        cta="Learn more"
    >
    Test and develop your app using the LangGraph server process locally.
    </Card>

    <Card
        title="Deploy to cloud"
        icon="cloud"
        href="/langgraph-platform/deployment-quickstart"
        arrow="true"
        cta="Learn more"
    >
    Run your app in a fully managed cloud deployment.
    </Card>

    <Card
        title="LangGraph Studio"
        icon="play"
        href="/langgraph-platform/langgraph-studio"
        arrow="true"
        cta="Learn more"
    >
    Visualize, debug, and interact with agent workflows.
    Includes integrations with LangSmith for tracing and evaluation.
    </Card>

</Columns>

## Features

<Columns cols={3}>

    <Card
        title="Streaming Support"
        icon="signal"
        href="/langgraph-platform/streaming"
        arrow="true"
        cta="Learn more"
    >
    Stream token outputs and intermediate states back to the client in real time,
    reducing wait times during long operations.
    </Card>

    <Card
        title="Background Runs"
        icon="clock"
        href="/langgraph-platform/background-run"
        arrow="true"
        cta="Learn more"
    >
    Run agents asynchronously for long-duration tasks (minutes to hours),
    with monitoring via polling endpoints or webhooks.
    </Card>

    <Card
        title="Burst Handling"
        icon="server"
        href="/langgraph-platform/data-plane#redis"
        arrow="true"
        cta="Learn more"
    >
    Use the built-in task queue to handle bursty request loads without data loss
    or service disruption.
    </Card>

    <Card
        title="Interrupt Handling"
        icon="split"
        href="/langgraph-platform/interrupt-concurrent"
        arrow="true"
        cta="Learn more"
    >
    Manage overlapping or rapid user inputs (“double texting”) without breaking
    agent state.
    </Card>

    <Card
        title="Checkpointers & Memory"
        icon="database"
        href="/oss/langgraph/persistence#checkpoints"
        arrow="true"
        cta="Learn more"
    >
    Persist agent state with built-in checkpointing and memory storage,
    removing the need for custom solutions.
    </Card>

    <Card
        title="Human-in-the-Loop"
        icon="user-check"
        href="/langgraph-platform/add-human-in-the-loop"
        arrow="true"
        cta="Learn more"
    >
    Insert human review or intervention into an agent run through dedicated APIs.
    </Card>

</Columns>
