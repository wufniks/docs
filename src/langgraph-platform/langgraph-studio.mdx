---
title: Overview
---

<Info>
  **Prerequisites**
  * [LangGraph Platform](index)
  * [LangGraph Server](langgraph-server)
  * [LangGraph CLI](langgraph-cli)
</Info>

LangGraph Studio is a specialized agent IDE that enables visualization, interaction, and debugging of agentic systems that implement the LangGraph Server API protocol. Studio also integrates with LangSmith to enable tracing, evaluation, and prompt engineering.

![](images/lg-platform.png)

## Features

Key features of LangGraph Studio:

* Visualize your graph architecture
* [Run and interact with your agent](invoke-studio)
* [Manage assistants](manage-assistants-studio)
* [Manage threads](threads-studio)
* [Iterate on prompts](iterate-graph-studio)
* [Run experiments over a dataset](run-evals-studio)
* Manage [long term memory](https://langchain-ai.github.io/langgraph/concepts/memory/)
* Debug agent state via [time travel](https://langchain-ai.github.io/langgraph/concepts/time-travel/)

LangGraph Studio works for graphs that are deployed on [LangGraph Platform](deployment-quickstart) or for graphs that are running locally via the [LangGraph Server](local-server).

Studio supports two modes:

### Graph mode

Graph mode exposes the full feature-set of Studio and is useful when you would like as many details about the execution of your agent, including the nodes traversed, intermediate states, and LangSmith integrations (such as adding to datasets and playground).

### Chat mode

Chat mode is a simpler UI for iterating on and testing chat-specific agents. It is useful for business users and those who want to test overall agent behavior. Chat mode is only supported for graph's whose state includes or extends [`MessagesState`](https://langchain-ai.github.io/langgraph/how-tos/graph-api/#messagesstate).

## Learn more

* See this guide on how to [get started](quick-start-studio) with LangGraph Studio.
