---
title: Model caches
---

[Caching LLM calls](/oss/how-to/chat_model_caching) can be useful for testing, cost savings, and speed.

Below are some integrations that allow you to cache results of individual LLM calls using different caches with different strategies.

<Columns cols={3}>
  <Card
    title="Azure Cosmos DB NoSQL Semantic Cache"
    icon="link"
    href="/oss/integrations/llm_caching/azure_cosmosdb_nosql"
    arrow="true"
    cta="View guide"
  >
  </Card>
</Columns>
