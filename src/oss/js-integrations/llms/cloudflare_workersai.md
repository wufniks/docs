---
title: CloudflareWorkersAI
---

This will help you get started with Cloudflare Workers AI [text completion models (LLMs)](/oss/concepts/text_llms) using LangChain. For detailed documentation on `CloudflareWorkersAI` features and configuration options, please refer to the [API reference](https://api.js.langchain.com/classes/langchain_cloudflare.CloudflareWorkersAI.html).

## Overview
### Integration details

| Class | Package | Local | Serializable | PY support | Package downloads | Package latest |
| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |
| [`CloudflareWorkersAI`](https://api.js.langchain.com/classes/langchain_cloudflare.CloudflareWorkersAI.html) | [`@langchain/cloudflare`](https://npmjs.com/@langchain/cloudflare) | ❌ | ✅ | ❌ | ![NPM - Downloads](https://img.shields.io/npm/dm/@langchain/cloudflare?style=flat-square&label=%20&) | ![NPM - Version](https://img.shields.io/npm/v/@langchain/cloudflare?style=flat-square&label=%20&) |

## Setup

To access Cloudflare Workers AI models you'll need to create a Cloudflare account, get an API key, and install the `@langchain/cloudflare` integration package.

### Credentials

Head [to this page](https://developers.cloudflare.com/workers-ai/) to sign up to Cloudflare and generate an API key. Once you've done this, note your `CLOUDFLARE_ACCOUNT_ID` and `CLOUDFLARE_API_TOKEN`.

### Installation

The LangChain Cloudflare integration lives in the `@langchain/cloudflare` package:

```{=mdx}
import IntegrationInstallTooltip from "@mdx_components/integration_install_tooltip.mdx";
<IntegrationInstallTooltip></IntegrationInstallTooltip>

<Npm2Yarn>
  @langchain/cloudflare @langchain/core
</Npm2Yarn>

```
## Instantiation

Now we can instantiate our model object and generate chat completions:


```typescript
// @lc-docs-hide-cell

// @ts-expect-error Deno is not recognized
const CLOUDFLARE_ACCOUNT_ID = Deno.env.get("CLOUDFLARE_ACCOUNT_ID");
// @ts-expect-error Deno is not recognized
const CLOUDFLARE_API_TOKEN = Deno.env.get("CLOUDFLARE_API_TOKEN");
```
```typescript
import { CloudflareWorkersAI } from "@langchain/cloudflare";

const llm = new CloudflareWorkersAI({
  model: "@cf/meta/llama-3.1-8b-instruct", // Default value
  cloudflareAccountId: CLOUDFLARE_ACCOUNT_ID,
  cloudflareApiToken: CLOUDFLARE_API_TOKEN,
  // Pass a custom base URL to use Cloudflare AI Gateway
  // baseUrl: `https://gateway.ai.cloudflare.com/v1/{YOUR_ACCOUNT_ID}/{GATEWAY_NAME}/workers-ai/`,
});
```

## Invocation


```typescript
const inputText = "Cloudflare is an AI company that "

const completion = await llm.invoke(inputText);
completion
```



```output
"Cloudflare is not an AI company, but rather a content delivery network (CDN) and security company. T"... 876 more characters
```


## Chaining

We can [chain](/oss/how-to/sequence/) our completion model with a prompt template like so:


```typescript
import { PromptTemplate } from "@langchain/core/prompts"

const prompt = PromptTemplate.fromTemplate("How to say {input} in {output_language}:\n")

const chain = prompt.pipe(llm);
await chain.invoke(
  {
    output_language: "German",
    input: "I love programming.",
  }
)
```



```output
"That's a simple but sweet statement! \n" +
  "\n" +
  'To say "I love programming" in German, you can say: "ICH LIEB'... 366 more characters
```


## API reference

For detailed documentation of all `CloudflareWorkersAI` features and configurations head to the API reference: https://api.js.langchain.com/classes/langchain_cloudflare.CloudflareWorkersAI.html
